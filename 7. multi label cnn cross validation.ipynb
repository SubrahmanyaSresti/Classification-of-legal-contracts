{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. DATA PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Conv1D, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import average_precision_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. TO SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading preprocessed dataset\n",
    "file_path = \"/Users/lalitaneeharikavajjhala/Desktop/Research credits /Data/preprocessed_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>we will issue a certificate of completion for each manager trainee who completes the initial training program we require to our satisfaction each such person will be referred to a a certified manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>elephant talk bear the risk of and shall indemnify against high usage fraud and bed of it elephant talk customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>subject to the term and condition of this agreement aimmune shall be responsible for the development of the product a set forth herein aimmune itself or with or through it affiliate and sublicensees shall use commercially reasonable effort to perform the development activity for the product to i achieve the development milestone set forth in section and ii obtain regulatory approval for the product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>ediets shall ensure that the ediets content complies with editorial guideline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obligation']</td>\n",
       "      <td>auriemma will participate in one recording session annually during the service period of not more than two hour not including travel time to record a radio advertising spot at a date and location to be mutually agreed upon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tag  \\\n",
       "0  ['obligation']   \n",
       "1  ['obligation']   \n",
       "2  ['obligation']   \n",
       "3  ['obligation']   \n",
       "4  ['obligation']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                            sentence  \n",
       "0                                                                                                                                                                                                            we will issue a certificate of completion for each manager trainee who completes the initial training program we require to our satisfaction each such person will be referred to a a certified manager  \n",
       "1                                                                                                                                                                                                                                                                                                   elephant talk bear the risk of and shall indemnify against high usage fraud and bed of it elephant talk customer  \n",
       "2  subject to the term and condition of this agreement aimmune shall be responsible for the development of the product a set forth herein aimmune itself or with or through it affiliate and sublicensees shall use commercially reasonable effort to perform the development activity for the product to i achieve the development milestone set forth in section and ii obtain regulatory approval for the product  \n",
       "3                                                                                                                                                                                                                                                                                                                                      ediets shall ensure that the ediets content complies with editorial guideline  \n",
       "4                                                                                                                                                                                     auriemma will participate in one recording session annually during the service period of not more than two hour not including travel time to record a radio advertising spot at a date and location to be mutually agreed upon  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing data head and extend the max column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tags from strings to lists\n",
    "df['tag'] = df['tag'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encodeing tags 'y'\n",
    "y = df['tag']\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard keras pre-processing\n",
    "maxlen = 200 # Highest word count is 691 and mean is 52; however, 691 is an outlier\n",
    "max_words = 2000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df.sentence)\n",
    "\n",
    "# Functions to transform text to feature_vectors \n",
    "def get_features(text_series):\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(947, 200) (947, 3)\n"
     ]
    }
   ],
   "source": [
    "# Calling function to create features 'X'\n",
    "X = get_features(df.sentence)\n",
    "\n",
    "# Transforming y\n",
    "y = multilabel.transform(df.tag)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   8, 577, 372],\n",
       "       [  0,   0,   0, ..., 105, 106, 109],\n",
       "       [  0,   0,   0, ...,  19,   1,  31],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  14,  11,  37],\n",
       "       [  0,   0,   0, ...,   1,  12,   9],\n",
       "       [  0,   0,   0, ..., 276,   5, 238]], dtype=int32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIAL ORIGINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 200, 20)           40000     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200, 20)           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 198, 300)          18300     \n",
      "                                                                 \n",
      " global_max_pooling1d_8 (Gl  (None, 300)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 903       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59203 (231.26 KB)\n",
      "Trainable params: 59203 (231.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "num_classes = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.6779 - categorical_accuracy: 0.2876 - val_loss: 0.6658 - val_categorical_accuracy: 0.5329 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6574 - categorical_accuracy: 0.3835 - val_loss: 0.6614 - val_categorical_accuracy: 0.3026 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6487 - categorical_accuracy: 0.3983 - val_loss: 0.6507 - val_categorical_accuracy: 0.5197 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.6336 - categorical_accuracy: 0.6050 - val_loss: 0.6286 - val_categorical_accuracy: 0.5724 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5984 - categorical_accuracy: 0.6479 - val_loss: 0.5840 - val_categorical_accuracy: 0.6447 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.5330 - categorical_accuracy: 0.7388 - val_loss: 0.5101 - val_categorical_accuracy: 0.7171 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4471 - categorical_accuracy: 0.7570 - val_loss: 0.4342 - val_categorical_accuracy: 0.7237 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.3641 - categorical_accuracy: 0.7901 - val_loss: 0.3750 - val_categorical_accuracy: 0.7697 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2986 - categorical_accuracy: 0.8149 - val_loss: 0.3293 - val_categorical_accuracy: 0.7697 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.2418 - categorical_accuracy: 0.8512 - val_loss: 0.2958 - val_categorical_accuracy: 0.7829 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1958 - categorical_accuracy: 0.8694 - val_loss: 0.2678 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1578 - categorical_accuracy: 0.8909 - val_loss: 0.2468 - val_categorical_accuracy: 0.8289 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1304 - categorical_accuracy: 0.8893 - val_loss: 0.2359 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.1095 - categorical_accuracy: 0.9140 - val_loss: 0.2276 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0905 - categorical_accuracy: 0.9124 - val_loss: 0.2206 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0719 - categorical_accuracy: 0.9157 - val_loss: 0.2172 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0641 - categorical_accuracy: 0.9256 - val_loss: 0.2170 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0559 - categorical_accuracy: 0.9273 - val_loss: 0.2196 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0480 - categorical_accuracy: 0.9339 - val_loss: 0.2211 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0404 - categorical_accuracy: 0.9289 - val_loss: 0.2262 - val_categorical_accuracy: 0.8224 - lr: 0.0010\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0891 - categorical_accuracy: 0.9091 - val_loss: 0.0264 - val_categorical_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0596 - categorical_accuracy: 0.9174 - val_loss: 0.0256 - val_categorical_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0495 - categorical_accuracy: 0.9256 - val_loss: 0.0266 - val_categorical_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0412 - categorical_accuracy: 0.9124 - val_loss: 0.0269 - val_categorical_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0358 - categorical_accuracy: 0.9322 - val_loss: 0.0268 - val_categorical_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0298 - categorical_accuracy: 0.9174 - val_loss: 0.0257 - val_categorical_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0276 - categorical_accuracy: 0.9224 - val_loss: 0.0141 - val_categorical_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0245 - categorical_accuracy: 0.9241 - val_loss: 0.0151 - val_categorical_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0210 - categorical_accuracy: 0.9224 - val_loss: 0.0149 - val_categorical_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0177 - categorical_accuracy: 0.9290 - val_loss: 0.0163 - val_categorical_accuracy: 0.9470 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0186 - categorical_accuracy: 0.9191 - val_loss: 0.0151 - val_categorical_accuracy: 0.9536 - lr: 0.0010\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0164 - categorical_accuracy: 0.9439 - val_loss: 0.0140 - val_categorical_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0133 - categorical_accuracy: 0.9356 - val_loss: 0.0133 - val_categorical_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0114 - categorical_accuracy: 0.9439 - val_loss: 0.0135 - val_categorical_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0108 - categorical_accuracy: 0.9439 - val_loss: 0.0140 - val_categorical_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0106 - categorical_accuracy: 0.9472 - val_loss: 0.0140 - val_categorical_accuracy: 0.9139 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0085 - categorical_accuracy: 0.9373 - val_loss: 0.0142 - val_categorical_accuracy: 0.9205 - lr: 0.0010\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0111 - categorical_accuracy: 0.9389 - val_loss: 0.0043 - val_categorical_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0108 - categorical_accuracy: 0.9439 - val_loss: 0.0043 - val_categorical_accuracy: 0.9073 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0087 - categorical_accuracy: 0.9373 - val_loss: 0.0046 - val_categorical_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0077 - categorical_accuracy: 0.9307 - val_loss: 0.0046 - val_categorical_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0088 - categorical_accuracy: 0.9439 - val_loss: 0.0046 - val_categorical_accuracy: 0.9007 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4)\n",
    "]\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_fold_train,\n",
    "        y_fold_train,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_fold_val, y_fold_val)\n",
    "    )\n",
    "\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Loss: 0.0404 - Val Loss: 0.2262\n",
      "Fold 2 - Train Loss: 0.0298 - Val Loss: 0.0257\n",
      "Fold 3 - Train Loss: 0.0186 - Val Loss: 0.0151\n",
      "Fold 4 - Train Loss: 0.0085 - Val Loss: 0.0142\n",
      "Fold 5 - Train Loss: 0.0088 - Val Loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "# Print the training and validation loss for each fold\n",
    "for fold in range(5):\n",
    "    print(\"Fold %d - Train Loss: %.4f - Val Loss: %.4f\" % (fold+1, train_loss[fold], val_loss[fold]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.2120 - categorical_accuracy: 0.8632\n",
      "loss: 0.21197573840618134\n",
      "categorical_accuracy: 0.8631578683853149\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(X_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "Precision Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Calculating loss and precision\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Precision Score: {:.2}\".format(average_precision_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIGHER ACCURACY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import array, asarray, zeros\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Conv1D, Dropout, SpatialDropout1D, Bidirectional, LSTM\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "file_path = \"/Users/lalitaneeharikavajjhala/Desktop/Research credits /Data/preprocessed_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Previewing data head and extend the max column width\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()\n",
    "\n",
    "# Converting tags from strings to lists\n",
    "df['tag'] = df['tag'].apply(lambda x: literal_eval(x))\n",
    "\n",
    "# Encoding tags 'y'\n",
    "y = df['tag']\n",
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard keras pre-processing\n",
    "maxlen = 200\n",
    "max_words = 2000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df.sentence)\n",
    "\n",
    "# Functions to transform text to feature_vectors\n",
    "def get_features(text_series):\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "# Calling function to create features 'X'\n",
    "X = get_features(df.sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 200, 100)          200000    \n",
      "                                                                 \n",
      " spatial_dropout1d_4 (Spati  (None, 200, 100)          0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 196, 64)           32064     \n",
      "                                                                 \n",
      " global_max_pooling1d_9 (Gl  (None, 64)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240771 (940.51 KB)\n",
      "Trainable params: 240771 (940.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True, stratify=y)\n",
    "\n",
    "# Define CNN model with Word2Vec embeddings\n",
    "filter_length = 300\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words, 100, input_length=maxlen))  \n",
    "model1.add(SpatialDropout1D(0.2))  \n",
    "model1.add(Conv1D(64, 5, activation='relu'))  \n",
    "model1.add(GlobalMaxPool1D())\n",
    "model1.add(Dense(128, activation='relu'))  \n",
    "model1.add(Dropout(0.5))  \n",
    "model1.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.6853 - accuracy: 0.3444 - val_loss: 0.6716 - val_accuracy: 0.3228 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6631 - accuracy: 0.4127 - val_loss: 0.6571 - val_accuracy: 0.3228 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6506 - accuracy: 0.4349 - val_loss: 0.6484 - val_accuracy: 0.4882 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6341 - accuracy: 0.5587 - val_loss: 0.6332 - val_accuracy: 0.4961 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6023 - accuracy: 0.6016 - val_loss: 0.6067 - val_accuracy: 0.4646 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5493 - accuracy: 0.6714 - val_loss: 0.5618 - val_accuracy: 0.5669 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4775 - accuracy: 0.6905 - val_loss: 0.5104 - val_accuracy: 0.5827 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4186 - accuracy: 0.7016 - val_loss: 0.4448 - val_accuracy: 0.7165 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3353 - accuracy: 0.8143 - val_loss: 0.3755 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2821 - accuracy: 0.8397 - val_loss: 0.3159 - val_accuracy: 0.8268 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2170 - accuracy: 0.8603 - val_loss: 0.2561 - val_accuracy: 0.8425 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1667 - accuracy: 0.8968 - val_loss: 0.2142 - val_accuracy: 0.8504 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1282 - accuracy: 0.8968 - val_loss: 0.1876 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0918 - accuracy: 0.9063 - val_loss: 0.1754 - val_accuracy: 0.8661 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0834 - accuracy: 0.9111 - val_loss: 0.1627 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 0.9143 - val_loss: 0.1565 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0551 - accuracy: 0.9302 - val_loss: 0.1565 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 0.9079 - val_loss: 0.1544 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 0.9508 - val_loss: 0.1635 - val_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 0.9206 - val_loss: 0.1617 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0324 - accuracy: 0.9397 - val_loss: 0.1603 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0264 - accuracy: 0.9397 - val_loss: 0.1611 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0546 - accuracy: 0.9398 - val_loss: 0.0130 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0340 - accuracy: 0.9271 - val_loss: 0.0153 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9398 - val_loss: 0.0168 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0286 - accuracy: 0.9287 - val_loss: 0.0173 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0229 - accuracy: 0.9414 - val_loss: 0.0189 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0254 - accuracy: 0.9223 - val_loss: 0.0046 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0204 - accuracy: 0.9319 - val_loss: 0.0049 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0184 - accuracy: 0.9493 - val_loss: 0.0043 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0193 - accuracy: 0.9208 - val_loss: 0.0039 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.9255 - val_loss: 0.0044 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0158 - accuracy: 0.9414 - val_loss: 0.0033 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0130 - accuracy: 0.9303 - val_loss: 0.0033 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0169 - accuracy: 0.9303 - val_loss: 0.0029 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0121 - accuracy: 0.9366 - val_loss: 0.0031 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0123 - accuracy: 0.9144 - val_loss: 0.0030 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 0.9445 - val_loss: 0.0035 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0110 - accuracy: 0.9255 - val_loss: 0.0032 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 0.9461 - val_loss: 0.0015 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0148 - accuracy: 0.9429 - val_loss: 0.0026 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9477 - val_loss: 0.0018 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0101 - accuracy: 0.9477 - val_loss: 0.0014 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9382 - val_loss: 0.0013 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9493 - val_loss: 0.0012 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 0.9477 - val_loss: 0.0012 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0098 - accuracy: 0.9525 - val_loss: 0.0014 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0093 - accuracy: 0.9366 - val_loss: 0.0012 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9445 - val_loss: 0.0013 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0066 - accuracy: 0.9540 - val_loss: 5.7762e-04 - val_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 0.9461 - val_loss: 5.0366e-04 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9445 - val_loss: 4.4547e-04 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9445 - val_loss: 4.4897e-04 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 0.9445 - val_loss: 4.4017e-04 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0073 - accuracy: 0.9366 - val_loss: 4.3549e-04 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 0.9461 - val_loss: 3.9761e-04 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 0.9429 - val_loss: 4.3119e-04 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0060 - accuracy: 0.9271 - val_loss: 3.5745e-04 - val_accuracy: 0.9286 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 0.9319 - val_loss: 3.7447e-04 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 0.9414 - val_loss: 3.4789e-04 - val_accuracy: 0.8968 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 0.9398 - val_loss: 3.5066e-04 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 0.9382 - val_loss: 3.4592e-04 - val_accuracy: 0.9444 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 0.9445 - val_loss: 3.4024e-04 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0056 - accuracy: 0.9398 - val_loss: 3.2522e-04 - val_accuracy: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.9445 - val_loss: 3.1126e-04 - val_accuracy: 0.9127 - lr: 1.0000e-04\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0052 - accuracy: 0.9429 - val_loss: 3.0688e-04 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9477 - val_loss: 3.0565e-04 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.9414 - val_loss: 3.0406e-04 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 0.9382 - val_loss: 3.0212e-04 - val_accuracy: 0.9127 - lr: 1.0000e-04\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0047 - accuracy: 0.9350 - val_loss: 2.9810e-04 - val_accuracy: 0.9127 - lr: 1.0000e-04\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.9429 - val_loss: 2.9508e-04 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0031 - accuracy: 0.9445 - val_loss: 2.9564e-04 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 0.9350 - val_loss: 2.9598e-04 - val_accuracy: 0.8968 - lr: 1.0000e-04\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9287 - val_loss: 2.9579e-04 - val_accuracy: 0.8968 - lr: 1.0000e-05\n",
      "Epoch 1/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 0.9255 - val_loss: 2.2817e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.9287 - val_loss: 2.2718e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.9303 - val_loss: 2.2650e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0050 - accuracy: 0.9303 - val_loss: 2.2579e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.9350 - val_loss: 2.2462e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 0.9208 - val_loss: 2.2343e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0028 - accuracy: 0.9271 - val_loss: 2.2281e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.9239 - val_loss: 2.2265e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.9271 - val_loss: 2.2260e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0032 - accuracy: 0.9239 - val_loss: 2.2224e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0030 - accuracy: 0.9366 - val_loss: 2.2182e-04 - val_accuracy: 0.9762 - lr: 1.0000e-05\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0043 - accuracy: 0.9414 - val_loss: 2.2185e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 0.9287 - val_loss: 2.2187e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 0.9303 - val_loss: 2.2184e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.9350 - val_loss: 2.2181e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 0.9334 - val_loss: 2.2178e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0051 - accuracy: 0.9192 - val_loss: 2.2178e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0040 - accuracy: 0.9271 - val_loss: 2.2174e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0044 - accuracy: 0.9319 - val_loss: 2.2172e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 0.9255 - val_loss: 2.2170e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.9255 - val_loss: 2.2164e-04 - val_accuracy: 0.9762 - lr: 1.0000e-06\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0038 - accuracy: 0.9271 - val_loss: 2.2163e-04 - val_accuracy: 0.9762 - lr: 1.0000e-07\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 0.9287 - val_loss: 2.2163e-04 - val_accuracy: 0.9762 - lr: 1.0000e-07\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0042 - accuracy: 0.9414 - val_loss: 2.2162e-04 - val_accuracy: 0.9762 - lr: 1.0000e-07\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0039 - accuracy: 0.9303 - val_loss: 2.2162e-04 - val_accuracy: 0.9762 - lr: 1.0000e-07\n",
      "Fold 1 - Train Loss: 0.0264 - Val Loss: 0.1611\n",
      "Fold 2 - Train Loss: 0.0229 - Val Loss: 0.0189\n",
      "Fold 3 - Train Loss: 0.0110 - Val Loss: 0.0032\n",
      "Fold 4 - Train Loss: 0.0061 - Val Loss: 0.0013\n",
      "Fold 5 - Train Loss: 0.0066 - Val Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=6, shuffle=True)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    history = model1.fit(\n",
    "        X_fold_train,\n",
    "        y_fold_train,\n",
    "        epochs=25,\n",
    "        batch_size=64,  # Increase batch size\n",
    "        callbacks=callbacks,\n",
    "        validation_data=(X_fold_val, y_fold_val)\n",
    "    )\n",
    "\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])\n",
    "\n",
    "# Print the training and validation loss for each fold\n",
    "for fold in range(5):\n",
    "    print(\"Fold %d - Train Loss: %.4f - Val Loss: %.4f\" % (fold+1, train_loss[fold], val_loss[fold]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIGH ACCURACY MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9105\n",
      "Test Loss: 0.18982639908790588\n",
      "Test Accuracy: 0.9105263352394104\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test data\n",
    "metrics = model1.evaluate(X_test, y_test)\n",
    "print(\"Test Loss: {}\".format(metrics[0]))\n",
    "print(\"Test Accuracy: {}\".format(metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/6 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "Precision Score: 0.97\n",
      "Recall: 0.8930232558139535\n",
      "F1 Score: 0.8943316883064705\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "thresholded_preds = (y_pred > 0.5).astype(int)  # Applying threshold for binary classification\n",
    "precision = precision_score(y_test, thresholded_preds, average = 'weighted')\n",
    "recall = recall_score(y_test, thresholded_preds, average = 'weighted')\n",
    "f1 = f1_score(y_test, thresholded_preds, average= 'weighted')\n",
    "print(\"Precision Score: {:.2}\".format(average_precision_score(y_test,y_pred)))\n",
    "# print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "[[0.9649912  0.00227412 0.78824747]]\n",
      "[('obligation', 'prohibition')]\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "# x = [\"Each Party shall return to the other all of the others Confidential Information and any other material, information or samples relating to the Product which have been provided or made available to the other and shall not retain any copies and the Parties further agree not to make any further use of each others Confidential Information or any other information, data or samples relating to the Product provided or made available by the other Party, except as necessary to comply with its statutory, regulatory or licensing obligations; provided, however, that Kitov may retain such material, information and/or samples relating to the Product as may be necessary for Kitov to continue to sell the Product as permitted by Section 5.4.4 below, following which, Kitov shall refrain from making any further use of Dexcels Confidential Information or any other information, data or samples and shall return any remaining Confidential Information and material, information or samples relating to the Product.\"]\n",
    "x = [\"The confidentiality obligations contained in this section XI shall not apply to the extent that the receiving Party (the 'Recipient') is required (a) to disclose information by law, order or regulation of a governmental agency or a court of competent jurisdiction , or (b) to disclose information to any governmental agency for purposes of obtaining approval to test or market a Product , provided in either case that the Recipient shall provide written notice thereof to the other Party and sufficient opportunity to object to any such disclosure or to request confidential treatment thereof.\"]\n",
    "xt = get_features(x)\n",
    "prediction = model.predict(xt)\n",
    "# probas = np.array(prediction)\n",
    "# labels = (probas > 0.5).astype(np.int)\n",
    "\n",
    "probas = (prediction > 0.5).astype(int)\n",
    "tags = multilabel.inverse_transform(probas)\n",
    "# tags = multilabel.inverse_transform(labels)\n",
    "\n",
    "print(prediction)\n",
    "# print(labels)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBLIGATION\n",
      "PROHIBITION\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(tags[0]).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligation prohibition\n"
     ]
    }
   ],
   "source": [
    "print(*tags[0], sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelTokenizer.pkl']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save tokenizer\n",
    "joblib.dump(tokenizer, \"/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelTokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelBinarizer_CNN.pkl']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save binarizer\n",
    "joblib.dump(multilabel, \"/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelBinarizer_CNN.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelModel_CNN.pkl']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, \"/Users/lalitaneeharikavajjhala/Desktop/Research credits /Models/MultiLabelModel_CNN.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
